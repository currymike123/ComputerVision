{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Object Detection\n",
    "****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Object detection</b> is the process of identifying and locating objects of interest in an image or video using computer vision techniques. It involves detecting the presence of objects and drawing bounding boxes around them to localize them in the image or video."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>Canny Edge Detector</b> is a popular edge detection technique due to its effectiveness in detecting edges while reducing noise and false edges. It can be applied to a wide range of computer vision tasks, such as object detection, image segmentation, and feature extraction.\n",
    "\n",
    "The Canny Edge Detector leverages the edge detecting power of the Sobel Kernel and is similar to the Sobel pipeline from the last module.\n",
    "\n",
    "<ol>\n",
    "  <li><p>Smoothing: The first step is to apply Gaussian smoothing to the input image to remove noise and make the edges smoother. This is done using a Gaussian filter.</p></li>\n",
    "  <li><p>Finding intensity gradients: Next, the intensity gradients of the image are calculated using the Sobel operator. The Sobel operator calculates the gradient magnitude and direction at each pixel of the image. This step highlights regions of the image where there are sudden changes in intensity.</p></li>\n",
    "  <li><p>Non-maximum suppression: In this step, the gradient magnitude is thinned out by keeping only the local maxima. This is done by examining each pixel and suppressing non-maximum values. The idea is to keep only those pixels that have the highest gradient values along the direction of the gradient.</p></li>\n",
    "  <li><p>Double thresholding: In this step, two thresholds are applied to the gradient magnitude to classify pixels as either strong, weak or non-edges. A pixel with a gradient magnitude higher than the upper threshold is classified as a strong edge, a pixel with a gradient magnitude lower than the lower threshold is classified as a non-edge, and a pixel with a gradient magnitude between the two thresholds is classified as a weak edge.</p></li>\n",
    "  <li><p>Edge tracking by hysteresis: Finally, in this step, the weak edges are traced and connected to strong edges to form complete edges. This is done by performing edge tracking using hysteresis, which means that weak edges that are connected to strong edges are also considered strong edges.</p></li>\n",
    "</ol> \n",
    "\n",
    "Hysteresis is a technique used in the Canny edge detector to connect weak edges to strong edges and form complete edges.\n",
    "\n",
    "In the double thresholding step of the Canny edge detector, pixels are classified as either strong, weak, or non-edges based on their gradient magnitude. Weak edges are those pixels with a gradient magnitude between the two thresholds, which may be caused by noise or other factors.\n",
    "\n",
    "Hysteresis is used to track and connect these weak edges to strong edges to form complete edges. The idea behind hysteresis is that if a weak edge pixel is connected to a strong edge pixel, it is likely part of an actual edge, and should be considered a strong edge itself.\n",
    "\n",
    "To implement hysteresis, the Canny edge detector traces all the edges starting from the strong edge pixels, while ignoring the weak and non-edge pixels. When it encounters a weak edge pixel, it checks whether it is connected to a strong edge pixel. If it is, then it is considered part of the edge and marked as a strong edge. If it is not connected to a strong edge pixel, then it is ignored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contours\n",
    "\n",
    "Contours are essentially the boundaries of objects in an image and can be used for a variety of purposes, such as object detection, recognition, and tracking.\n",
    "\n",
    "By finding contours in an image, we can extract more detailed information about the shapes of the objects present in the image. Contours are essentially the boundaries of objects in an image, and they can be used to segment objects or regions of interest, calculate their areas or perimeters, or perform other analyses.\n",
    "\n",
    "Moreover, by applying different contour finding algorithms in OpenCV, we can extract contours of different levels of complexity, such as finding the outermost contours, inner contours, or even hierarchical contours, which represent the nesting of objects within each other.\n",
    "\n",
    "By using cv2.findContours(), we can extract the contours of objects in an image and then use those contours to perform various operations on the objects, such as measuring their area, computing their perimeter, or applying a mask to them. We can also use the hierarchy information returned by cv2.findContours() to analyze the topology of the objects in the image, such as determining which objects are inside or outside of other objects.\n",
    "\n",
    "<b>image</b>: The input image. This should be a grayscale or binary image (i.e., an image with only two values: black and white). The contours are extracted from the white regions of the image.\n",
    "\n",
    "<b>mode</b>: The mode of contour retrieval. This determines which contours are retrieved and how they are represented. The most common modes are cv2.RETR_EXTERNAL, which retrieves only the outermost contours, and cv2.RETR_TREE, which retrieves all the contours and their hierarchical relationships.\n",
    "\n",
    "<b>method</b>: The method of contour approximation. This determines how the contours are approximated or simplified. The most common method is cv2.CHAIN_APPROX_SIMPLE, which approximates the contours using only their endpoints and discards any redundant points.\n",
    "\n",
    "<b>offset</b>: An optional argument used to specify an offset that should be added to the coordinates of the contours. This can be useful in cases where the contours need to be drawn on a different image or at a different location.\n",
    "\n",
    "The hierarchy array has the same number of elements as the number of contours found in the image. Each element of the hierarchy array contains four integers: [Next, Previous, First_Child, Parent]. These integers are indices of the contour hierarchy, and they have the following meanings:\n",
    "\n",
    "<ol>\n",
    "<li>Next: index of the next contour at the same hierarchical level.</li>\n",
    "<li>Previous: index of the previous contour at the same hierarchical level.</li>\n",
    "<li>First_Child: index of the first contour that is a child of the current contour.</li>\n",
    "<li>Parent: index of the parent contour of the current contour.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding Box\n",
    "\n",
    "A bounding box is a rectangle that completely encloses an object or a region of interest in an image. It is typically represented by the coordinates of its top-left corner, as well as its width and height. Bounding boxes are useful in computer vision tasks such as object detection, where we may want to locate and isolate specific objects within an image.\n",
    "\n",
    "We can also obtain the bounding box coordinates of a contour using the cv2.boundingRect() function. This function takes the contour as an argument and returns the (x, y) coordinates of the top-left corner of the bounding box, as well as its width and height. With this information, we can draw a bounding box around the contour using cv2.rectangle()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
