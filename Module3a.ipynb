{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3a: Image Compression\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we represent the same amount of data while taking up less memory.  Image Compression!  Let's go through a simple example. \n",
    "\n",
    "Let's begin with how our eye works.\n",
    "\n",
    "<img src=\"Graphics/eye.png\">\n",
    "\n",
    "\"Crudely speaking, the human eyes is a spherical camera with a 20mm focal length...The iris controls the amount of light passing through the lens by controlling the size of the pupil...The retina is unevenly populated with sensor cells.  An area near the center of the retina, called the fovea, has a very dense concentration of color receptors, called cones.  Away from the center, the density of cones decreases while the density of black and white receptors, the rods, increases.\" (Computer Vision, Linda Shapiro, 2000)<br><br>\n",
    "\n",
    "Our visual system is interpreting color on top of the black and white information in our peripheral vision.  The person sitting next to you might appear in color (you could have color blindness) but your eye is mainly capturing black and white information.  Since your peripheral vision has a limited amount of color receptors (cones), the color information needs to be shared among a large section of black and white receptors (rods).  Our brains combine the cone's color information with the neighboring rod's black and white information producing a color image.<br><br>\n",
    "\n",
    "Let's try to use our brains technique in an image compression algorithm <br>\n",
    "\n",
    "|| **0** | **1** | **2** |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| **0** |  55,100,200  |  74,124,100  | 89,210,10  |\n",
    "| **1** |  124,74,191  |  174,43,34  |  201,142,60  |\n",
    "| **2** |  191,50,10  |  215,111,84  |  245,139,81  |\n",
    "\n",
    "How much memory is used to store one color image of size 200 pixels by 200 pixels? Which contains 40,000 individual pixels, each containing three 8 bit Integers.<br> \n",
    "\n",
    "40,000 pixels x 24 bits (RGB) = 960,000 bits = 120,000 bytes = 0.12 megabytes\n",
    "\n",
    "Simple approach.  Two seperate arrays.  \n",
    "\n",
    "The first contains the brightness values of all the pixels. This can be saved as one value, one 8 Bit Integer, stored in a 2D array ([]). The second contains the RGB pixel values of every other row. This can be saved in 3 values, three 8 bit Integers, stored in a 3D array [[[]]].   \n",
    "\n",
    "1)  All the Brightness values. GreyScale\n",
    "2)  Every other row of RGB vales. \n",
    "\n",
    "40,000 pixels x 8 bits (Greyscale) = 320,000 bits = 40,000 bytes = 0.04 megabytes\n",
    "20,000 pixels x 24 bits (RGB) = 480,000 bits =  60,000 bytes = 0.06 megabytes\n",
    "\n",
    "We saved 0.02 megabytes!  A 17% savings!  Not bad at all for such a simple approach.\n",
    "\n",
    "|| **0** | **1** | **2** |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| **0** |  226,226,226  |  226,226,226  | 226,226,226  |\n",
    "| **1** |  124  |  124  |  124  |\n",
    "| **2** |  40,40,40  |  40,40,40  |  40,40,40  |\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('opencv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
