{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Presence\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction\n",
    "\n",
    "A technique called background subtraction makes it possible to detect the presence of people or other objects in a scene, and to distinguish the pixels which belong to them from those which do not. The technique operates by comparing each frame of video with a stored image of the scene's background, captured at a point in time when the scene was known to be empty. For every pixel in the frame, the absolute difference is computed between its color and that of its corresponding pixel in the stored background image; areas which are very different from the background are likely to represent objects of interest. Background subtraction works well in heterogeneous environments, but it is very sensitive to changes in lighting conditions, and depends on objects of interest having sufficient contrast against the background scene.\n",
    "\n",
    "The advantage of Background Subtraction is it's ability to track objects that have entered the scene but have stopped moving.  For example, a car that has pulled over and parked on the side of the road.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you create a background frame?\n",
    "\n",
    "In most situations you will not have access to a clean background frame.  We will need a process to create one for a dynamic scene.  To create a background frame we are going to capture 100 frames of the scene with the camera.  Then average the frames together to create a background frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if webcam is successfully opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Parameters\n",
    "num_frames_for_background = 100\n",
    "count = 0\n",
    "\n",
    "# Initialize a running sum of frames\n",
    "background_accumulator = None\n",
    "\n",
    "while count < num_frames_for_background:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to float\n",
    "    float_frame = frame.astype(np.float32)\n",
    "\n",
    "    # Initialize or accumulate the frames\n",
    "    if background_accumulator is None:\n",
    "        background_accumulator = float_frame\n",
    "    else:\n",
    "        background_accumulator += float_frame\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    cv2.imshow(\"Capturing Background\", frame)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Calculate the average to obtain the background frame\n",
    "background_frame = (background_accumulator / num_frames_for_background).astype(np.uint8)\n",
    "\n",
    "# Show the background frame\n",
    "cv2.imshow(\"Background Frame\", background_frame)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction Pipeline\n",
    "\n",
    "<ol>\n",
    "    <li>Background Model Creation: A reference frame or a set of frames, usually when no objects of interest are present, is chosen as the background model.</li>\n",
    "    <li>Difference Computation: For every incoming frame, compute the absolute difference between its pixel values and the corresponding pixel values of the background model.</li>\n",
    "    <li>Thresholding: Pixels where the difference exceeds a certain threshold are marked as foreground pixels, and others as background.</li>\n",
    "    <li>Post-processing: Apply techniques like morphological operations to remove noise and fill small gaps.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open the video file or webcam\n",
    "cap = cv2.VideoCapture('video_file.mp4') # or 0 for webcam\n",
    "\n",
    "# Read the first frame and use it as the background. Or implement the above code. \n",
    "ret, background_img = cap.read()\n",
    "\n",
    "while ret:\n",
    "    # Read the next frame\n",
    "    ret, current_frame_img = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Compute the absolute difference\n",
    "    difference = cv2.absdiff(background_img, current_frame_img)\n",
    "    \n",
    "    # Convert to grayscale (assuming the video is color)\n",
    "    grayscale = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply a threshold to detect presence\n",
    "    _, thresholded = cv2.threshold(grayscale, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Display the result\n",
    "    cv2.imshow('Presence Detection', thresholded)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Frame Differencing and Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize the webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if webcam is successfully opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Get the first frame for initialization\n",
    "ret, prev_frame = cap.read()\n",
    "ret, current_frame = cap.read()\n",
    "\n",
    "# Initialize the background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
    "\n",
    "while ret:\n",
    "    # Frame Differencing\n",
    "    frame_diff = cv2.absdiff(prev_frame, current_frame)\n",
    "    gray_diff = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresholded_diff = cv2.threshold(gray_diff, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Background Subtraction\n",
    "    fg_mask = bg_subtractor.apply(current_frame)\n",
    "\n",
    "    # Combine the results of both methods\n",
    "    combined_mask = cv2.bitwise_or(thresholded_diff, fg_mask)\n",
    "\n",
    "    # Find contours to track the objects\n",
    "    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw bounding boxes around detected objects\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:  # filter small contours to remove noise\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(current_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Object Tracking', current_frame)\n",
    "\n",
    "    # Prepare for next iteration\n",
    "    prev_frame = current_frame.copy()\n",
    "    ret, current_frame = cap.read()\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
