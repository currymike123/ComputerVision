{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Presence\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction\n",
    "\n",
    "A technique called background subtraction makes it possible to detect the presence of people or other objects in a scene, and to distinguish the pixels which belong to them from those which do not. The technique operates by comparing each frame of video with a stored image of the scene's background, captured at a point in time when the scene was known to be empty. For every pixel in the frame, the absolute difference is computed between its color and that of its corresponding pixel in the stored background image; areas which are very different from the background are likely to represent objects of interest. Background subtraction works well in heterogeneous environments, but it is very sensitive to changes in lighting conditions, and depends on objects of interest having sufficient contrast against the background scene.\n",
    "\n",
    "The advantage of Background Subtraction is it's ability to track objects that have entered the scene but have stopped moving.  For example, a car that has pulled over and parked on the side of the road.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you create a background frame?\n",
    "\n",
    "In most situations you will not have access to a clean background frame.  We will need a process to create one for a dynamic scene.  To create a background frame we are going to capture 100 frames of the scene with the camera.  Then average the frames together to create a background frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if webcam is successfully opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Parameters\n",
    "num_frames_for_background = 100\n",
    "count = 0\n",
    "\n",
    "# Initialize a running sum of frames\n",
    "background_accumulator = None\n",
    "\n",
    "while count < num_frames_for_background:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to float\n",
    "    float_frame = frame.astype(np.float32)\n",
    "\n",
    "    # Initialize or accumulate the frames\n",
    "    if background_accumulator is None:\n",
    "        background_accumulator = float_frame\n",
    "    else:\n",
    "        background_accumulator += float_frame\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    cv2.imshow(\"Capturing Background\", frame)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Calculate the average to obtain the background frame\n",
    "background_frame = (background_accumulator / num_frames_for_background).astype(np.uint8)\n",
    "\n",
    "# Show the background frame\n",
    "cv2.imshow(\"Background Frame\", background_frame)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction Pipeline\n",
    "\n",
    "<ol>\n",
    "    <li>Background Model Creation: A reference frame or a set of frames, usually when no objects of interest are present, is chosen as the background model.</li>\n",
    "    <li>Difference Computation: For every incoming frame, compute the absolute difference between its pixel values and the corresponding pixel values of the background model.</li>\n",
    "    <li>Thresholding: Pixels where the difference exceeds a certain threshold are marked as foreground pixels, and others as background.</li>\n",
    "    <li>Post-processing: Apply techniques like morphological operations to remove noise and fill small gaps.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, background_img = cap.read()\n",
    "alpha = 0.02  # Weight factor to update the background. Smaller values make the update slower.\n",
    "\n",
    "while ret:\n",
    "    ret, current_frame_img = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    difference = cv2.absdiff(background_img, current_frame_img)\n",
    "    grayscale = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, thresholded = cv2.threshold(grayscale, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Noise reduction using morphological operations\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    opened = cv2.morphologyEx(thresholded, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Find contours and draw bounding boxes\n",
    "    contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:  # Filter out small areas to reduce noise\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(current_frame_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Update the background model\n",
    "    background_img = cv2.addWeighted(background_img, 1 - alpha, current_frame_img, alpha, 0)\n",
    "\n",
    "    cv2.imshow('Presence Detection', thresholded)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Frame Differencing and Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize the webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if webcam is successfully opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Get the first frame for initialization\n",
    "ret, prev_frame = cap.read()\n",
    "ret, current_frame = cap.read()\n",
    "\n",
    "# Initialize the background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
    "\n",
    "while ret:\n",
    "    # Frame Differencing\n",
    "    frame_diff = cv2.absdiff(prev_frame, current_frame)\n",
    "    gray_diff = cv2.cvtColor(frame_diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresholded_diff = cv2.threshold(gray_diff, 25, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Background Subtraction\n",
    "    fg_mask = bg_subtractor.apply(current_frame)\n",
    "\n",
    "    # Combine the results of both methods\n",
    "    combined_mask = cv2.bitwise_or(thresholded_diff, fg_mask)\n",
    "\n",
    "    # Find contours to track the objects\n",
    "    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw bounding boxes around detected objects\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:  # filter small contours to remove noise\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(current_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Object Tracking', current_frame)\n",
    "\n",
    "    # Prepare for next iteration\n",
    "    prev_frame = current_frame.copy()\n",
    "    ret, current_frame = cap.read()\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
