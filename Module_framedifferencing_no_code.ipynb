{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Detecting Motion\n",
    "****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Frame Differencing\n",
    "\n",
    "<b>Frame differencing</b> is a popular technique in computer vision that enables detection of movement or changes between consecutive frames in a video stream. It uses the process of computing the difference between pixel intensities of consecutive frames in a video. The resulting difference image, called a motion mask, reveals areas where changes have occurred.\n",
    "\n",
    " In this technique, each pixel in a video frame F1 is compared with its corresponding pixel in the subsequent frame F2. The difference in color and/or brightness between these two pixels is a measure of the amount of movement in that particular location. These differences can be summed across all of the pixels' locations, in order to provide a single measurement of the aggregate movement within the video frame. In some motion detection implementations, the video frame is spatially subdivided into a grid of cells, and the values derived from frame differencing are reported for each of the individual cells. For accuracy, the frame differencing algorithm depends on relatively stable environmental lighting, and on having a stationary camera (unless it is the motion of the camera which is being measured).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it work\n",
    "\n",
    "Given two consecutive frames \\( f_1 \\) and \\( f_2 \\), frame differencing computes their absolute difference to create a new image \\( D \\):\n",
    "\n",
    " D(x,y) = |f_2(x,y) - f_1(x,y)| \n",
    "\n",
    "The resulting image \\( D \\) will have higher intensity values in regions where there's significant change, highlighting movement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Frame Differencing Pipeline\n",
    "  \n",
    "  <ol>\n",
    "  <li>Difference Computation: For every incoming frame, compute the absolute difference between its pixel values and the corresponding pixel values of the background model.</li>\n",
    "    <li>Thresholding: Pixels where the difference exceeds a certain threshold are marked as foreground pixels, and others as background.</li>\n",
    "    <li>Post-processing: Apply techniques like morphological operations to remove noise and fill small gaps.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def compute_difference(frame1, frame2):\n",
    "    return cv2.absdiff(frame1, frame2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, reference_frame = cap.read()\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if no ret:\n",
    "        break\n",
    "\n",
    "    diff = compute_difference(reference_frame, frame)\n",
    "    gray_diff = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    _, threshold_val = cv2.threshold(gray_diff, 100, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"Motion Detection\", threshold_val)\n",
    "\n",
    "    reference_frame = frame.copy()\n",
    "\n",
    "    if cv2.waitKey(1)  & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project\n",
    "\n",
    "Develop a system that monitors a video feed (from a webcam or security camera) and sends an alert whenever significant motion is detected. This project will use frame differencing to identify motion in the video stream.  Utlizing the summing of the differences of all the pixel values to create a threshold for movement in the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(frame, \"Motion!\", (10,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
